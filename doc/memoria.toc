\babel@toc {spanish}{}\relax 
\contentsline {chapter}{Índice de figuras}{\es@scroman {iii}}{chapter*.2}%
\contentsline {chapter}{Índice de tablas}{\es@scroman {iv}}{chapter*.3}%
\contentsline {chapter}{Índice de algoritmos}{\es@scroman {v}}{chapter*.4}%
\contentsline {chapter}{Resumen}{1}{chapter*.5}%
\contentsline {chapter}{\numberline {1}Introduction}{3}{chapter.1}%
\contentsline {section}{\numberline {1.1}Context}{3}{section.1.1}%
\contentsline {section}{\numberline {1.2}Objectives}{3}{section.1.2}%
\contentsline {subsection}{\numberline {1.2.1}Main objective}{3}{subsection.1.2.1}%
\contentsline {subsection}{\numberline {1.2.2}Specific objectives}{3}{subsection.1.2.2}%
\contentsline {chapter}{\numberline {2}Theoretical framework}{5}{chapter.2}%
\contentsline {section}{\numberline {2.1}Problem Definition}{5}{section.2.1}%
\contentsline {section}{\numberline {2.2}Mono and Multi-modal Image Registration}{5}{section.2.2}%
\contentsline {section}{\numberline {2.3}Rigid and Non-rigid Registration}{5}{section.2.3}%
\contentsline {section}{\numberline {2.4}Image Warping}{6}{section.2.4}%
\contentsline {section}{\numberline {2.5}Diffeomorphism}{6}{section.2.5}%
\contentsline {section}{\numberline {2.6}Classical Methods}{6}{section.2.6}%
\contentsline {section}{\numberline {2.7}Deep learning-based methods}{6}{section.2.7}%
\contentsline {subsection}{\numberline {2.7.1}U-Net}{6}{subsection.2.7.1}%
\contentsline {section}{\numberline {2.8}Transformers}{6}{section.2.8}%
\contentsline {subsection}{\numberline {2.8.1}Mechanism of Self-attention}{6}{subsection.2.8.1}%
\contentsline {subsection}{\numberline {2.8.2}Encoder Block}{7}{subsection.2.8.2}%
\contentsline {subsection}{\numberline {2.8.3}Decoder Block}{7}{subsection.2.8.3}%
\contentsline {subsection}{\numberline {2.8.4}Multi-head Self-attention}{7}{subsection.2.8.4}%
\contentsline {section}{\numberline {2.9}Vision Transformers}{7}{section.2.9}%
\contentsline {section}{\numberline {2.10}SymTrans}{8}{section.2.10}%
\contentsline {subsection}{\numberline {2.10.1}Convolution-based Efficient Multi-head Self-attention (CEMSA)}{8}{subsection.2.10.1}%
\contentsline {chapter}{\numberline {3}Methodology}{13}{chapter.3}%
\contentsline {section}{\numberline {3.1}Proposed Architecture}{13}{section.3.1}%
\contentsline {section}{\numberline {3.2}Image Similarity Metric}{13}{section.3.2}%
\contentsline {chapter}{\numberline {4}Experiments}{15}{chapter.4}%
\contentsline {section}{\numberline {4.1}Dataset and Metrics}{15}{section.4.1}%
\contentsline {section}{\numberline {4.2}Baseline Methods}{15}{section.4.2}%
\contentsline {section}{\numberline {4.3}Implementation Details}{15}{section.4.3}%
\contentsline {section}{\numberline {4.4}Results}{15}{section.4.4}%
\contentsline {subsection}{\numberline {4.4.1}Quantitative Results}{15}{subsection.4.4.1}%
\contentsline {subsection}{\numberline {4.4.2}Qualitative Results}{15}{subsection.4.4.2}%
\contentsline {subsection}{\numberline {4.4.3}Computational Complexity}{15}{subsection.4.4.3}%
\contentsline {chapter}{\numberline {5}Conclusion and Limitations}{16}{chapter.5}%
\contentsline {section}{\numberline {5.1}Conclusion}{16}{section.5.1}%
\contentsline {section}{\numberline {5.2}Limitations}{16}{section.5.2}%
\contentsline {chapter}{\numberline {A}Annex A}{18}{appendix.Alph1}%
\contentsline {chapter}{Bibliografía}{19}{appendix*.7}%
